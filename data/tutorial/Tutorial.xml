<?xml version="1.0" encoding="UTF-8"?> 
<infoPages> 
	<infoPage next="SINGLE_PARTS" id="OBJECT_PARTS"> 
		<text>Terminology: objects and parts. An object is usually the organism itself, which contains parts. An example object would be the human face and example parts would be the eyes, nose and mouth.</text> 
		<image filename="data/tutorial/images/faceparts.jpg" caption="Parts of the object"/> 
	</infoPage> 
	<infoPage next="MULTIPLE_PARTS" id="SINGLE_PARTS"> 
		<text>Single Parts. Some characters consist of single parts and their absence/presence or other property. An example is eye color. It only involves the eye and its property, color.</text> 
		<image filename="data/tutorial/images/facesinglepart.jpg" caption="Example single part"/>
	</infoPage> 
	<infoPage next="RIGID_CONFIG" id="MULTIPLE_PARTS"> 
		<text>Multiple Parts. Other characters consist of multiple parts and their properties or relationships. An example is the distance between the eyes. It involves the left and right eyes and their relationship, the distance between them.	</text> 
		<image filename="data/tutorial/images/facemultipleparts.jpg" caption="Example multiple parts"/>
	</infoPage> 
	<infoPage next="TRAINING_IMAGES" id="RIGID_CONFIG"> 
		<text>Rigid Configuration of Parts. It is important to recognize when the configuration of parts is mostly rigid. An example of a rigid configuration of parts is the face. The eyes are always above the nose, the nose is always above the mouth, etc. The configuration of the eyes, nose and mouth are consistent and do not vary much.</text> 
		<image filename="data/tutorial/images/rigid.jpg" caption="Example rigid configuration of parts"/> 
	</infoPage> 
	<infoPage next="ANNOTATION" id="TRAINING_IMAGES"> 
		<text>Algorithm Requirements: training and testing images are required. For computer vision algorithms to work, we need training images: we need many images and their annotations to train our system. For each character, images need annotation that specifies the relevant parts and their relationships if applicable. We also need test images: test images do not require annotations unless one desires to evaluate the accuracy of the algorithm.</text> 
		<image filename="data/tutorial/images/baseline.jpg" caption="Example training image"/> 
		<image filename="data/tutorial/images/polygon.jpg" caption="Example corresponding annotation"/> 
	</infoPage> 
	<infoPage next="BOUNDING_BOX" id="ANNOTATION"> 
		<text>Annotation. There are three options for annotating parts in images: point, bounding box or polygon.</text> 
		<image filename="data/tutorial/images/boundingbox.jpg" caption="Bounding box"/>
		<image filename="data/tutorial/images/polygon.jpg" caption="Polygon"/>
	</infoPage> 
	<infoPage next="POLYGON" id="BOUNDING_BOX"> 
		<text>Bounding box. A bounding box is a box that encloses a part. A rule of thumb is to choose a bounding box for parts that do not articulate much. An example would be a tooth, which cannot articulate, bend, etc. The bounding box is currently supported by Morphobank.</text> 
		<image filename="data/tutorial/images/boundingbox.jpg" caption="Annotating with bounding boxes"/> 
	</infoPage> 
	<infoPage next="IMAGE_SHARPNESS" id="POLYGON"> 
		<text>Polygon. Use a polygon when a part is articulated. For example, a tail of an animal would be a good candidate for a polygon annotation because it can bend a lot. Make sure the polygon is tight around the part.</text> 
		<image filename="data/tutorial/images/polygon.jpg" caption="Annotating with polygons"/>
	</infoPage> 
	<!--<infoPage next="IMAGE_SHARPNESS" id="ANNOTATION_PART_RELATIONSHIPS"> 
		<text>Annotating Relation Between Parts. Use a bounding box or polygon depending on if the part can vary in articulation. Then label the relationship between the parts: distance, orientation, etc.</text> 
		<image filename="data/tutorial/images/partrelationships.jpg" caption="Annotating part relationships"/> 
	</infoPage> -->
	<infoPage next="WELL_CONTRASTED" id="IMAGE_SHARPNESS"> 
		<text>Miscellaneous Terminology: Image sharpness. Image sharpness is subjective but also not difficult to evaluate. A rule of thumb is to eliminate images that are too blurry to the human eye. See the example.</text> 
		<image filename="data/tutorial/images/baseline.jpg" caption="Sharp enough"/> 
		<image filename="data/tutorial/images/notsharp.jpg" caption="Not sharp enough"/> 
	</infoPage> 
	<infoPage next="NO_MORE_PAGES" id="WELL_CONTRASTED"> 
		<text>Miscellaneous Terminology: Well-constrasted. Well-contrasted refers to the contrast of the image. It is subjective but also not difficult to evaluate. See the example.</text> 
		<image filename="data/tutorial/images/baseline.jpg" caption="Better contrast"/> 
		<image filename="data/tutorial/images/poorcontrast.jpg" caption="Poorer contrast"/> 
	</infoPage> 
</infoPages>
