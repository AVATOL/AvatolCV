This document supercedes information in JIRAs, comments, etc, and will capture all aspects of the avatol_cv data pipeline, including the API between avatol_cv and the algorithms.  

This document is organized following the data pipeline, starting with 
what we get from Morphobank.

Definitions/assumptions:

 -  bundle - the directory containing all the information downloaded for a particular 
matrix, plus any files generated within that directory by our processing.  Each is
positioned under the matrix_downloads dir. For example, the BAT bundle is positioned here:

 -  presence/absence - we are focusing now strictly on characters who have states present/absent.

 -  simple characters - we are focusing now strictly on simple characters, i.e. single teeth, 
rather than compound characters that involve multiple sinmple teeth  (distance between toothx and toothy)

 - matlab will be positioned at the root directory of the downloaded matrix's data area, i.e.

/nfs/guille/bugid/bugid/AVATOL/av_cv/git/avatol_cv/matrix_downloads/BAT



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
PHASE 1 - ingesting downloaded Morphobank (MB) info
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

- avatol_cv uses information from the DOWNLOADED MATRIX *_sdd.xml file 
in conjunction with separate ANNOTATION files.  The latter files capture 
information captured when the user creates annotations in MB

- annotation files live under <bundle_root>/annotations 

- annotation files are named by the character and media file they represent, 
and contain one or more lines, each representing an annotation in MB
  
In  <charId>_<mediaId>.txt
 
    <coordinates>:<characterID>:<characterName>:<characterStateId>:<characterStateName>

where coordinates can be

point   : x1,y1
box     : x1,y1;x2,y2
polygon : x1,y1;x2,y2;x3,y3...
        
... where x and y coordinates represent a point in the image using percent width and percent height, origin is upper left. So, a point in the center top of an image would have coordinates 50.0, 0.0

for example, in c427749_m328533.txt:

       33.2,43.678:c427749:Upper I1 presence:s946108:I1 present
       50.6,60.50:c427749:Upper I1 presence:s946108:I1 present




===============================================================================
PHASE 1 - steps
===============================================================================

1. avatol_cv finds all annotation files. Files found signal what training data is in play. 

2. we assume the downloaded matrix data is created by having the user specify columns
and rows of interest, so all the cells represented in the downloaded data are either 
cells with training data or cells to score.  One nuance is that cells that have been scored as 
"not present" (i.e. absent) won't have annotations.  So, avatol_cv scans the _sdd.xml file for 
these.  

3. avatol_cv uses the annotation data and the "not present" training samples to generate input files 
that collect all the information for each character in one file for consumption by the algorithms.  
This shields the algorithms from the need to parse the _sdd.xml file 

- the naming convention for these files is:

  .../matrix_downloads/<bundle_root>/input/sorted_input_data_<characterID>_<characterName>.txt

It has lines that represent positive training examples, negative training examples, and images to score:

      training_data|<relative path of mediafile>|<characterStateID>|<characterStateName>|<relative path of annotation file>|<taxonID>|<line number in annotations file>
      training_data|<relative path of media file>|<characterStateID>|<characterStateName>|NA|<taxonID>|NA
      image_to_score|<relative path of media file>|<taxonID>|<relative path of annotation file>|<taxonID>|<line number in annotations file>

for example,

  .../matrix_downloads/BAT/input/sorted_input_data_c427749_Upper I1 presence.txt

has lines like:

       training_data|media/M328543_Thyroptera tricolor AMNH239080Fvent.jpg|s946108|I1 present|annotations/c427749_m328543.txt|t281048|1

       training_data|media/M283883_.jpg|s946109|I1 absent|NA|t171416|NA

       image_to_score|media\M283379.jpg|t171198|annotations\m283379_c427749.txt|1




4. filtering for DPM

DPM special case 1: For DPM, the algorithm works by looking at all the training data for all 
the characters at the same time.  The notion of focusing on one character at
a time doesn't really make sense, but since that is the general use case we 
decided on for a UI "session", we will work around it.  How we do this is described below

DPM special case 2: For DPM, we are currently performing "within taxon training and scoring"
Andrea complied with this approach by filling in the BAT matrix with specimens per row vs taxon
per row.  Each specimen has the original taxon name plus a specimen ID number (hers not the specimen
id from the db), and gets its own taxonID from the db.  When my system sees a file in the bundle root
called "specimentPerRowMarker.txt" it activates special code that maps all these taxonIDs to one "true"
taxonID, so that our system can know these specimens as from the same taxon.  For the 
DPM case, then, we only pass data to the algorithm belonging to a specific taxon.

DPM special case 3: Cells might have more than one image, where each image is a different view.

DPM special case 4: currently can only handle presence absence of "simple" characters (i.e. not characters
that involve, say, multiple teeth)

So the sequence of UI steps:

- ask which character is of interest
- questionnaire
- choose DPM
- ask user which of the characters are "simple" characters
- ask which taxa are desired for training
- ask which view is desired

System then filters the input file for the character into a new file of the same format that 
 has relevant data for that taxon and view, but all simple characters.  That file is located at

<bundleRoot>/input/DPM/<taxonID>/<simpleCharIDList>/<viewID>/sorted_input_data_<charID>_<charName>.txt

for example, 

matrix_downloads/BAT/input/DPM/t281048/c427749c427753c427754c427760/v3540/sorted_input_data_c427749_Upper I1 presence.txt

The lines of that file have the same format as

.../matrix_downloads/<bundle_root>/input/sorted_input_data_<characterID>_<characterName>.txt

UPDATE - DPM now has:
REGIME1 - within taxon training and scoring
REGIME2 - score novel taxa after training on different  (which maps better to the morphobank scoring case)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
PHASE 2 - PASSING INFORMATION TO ALGORITHMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For CRF, information passed in is 

 - inputFilePathname is  <bundle_root>/input/sorted_input_data_<characterID>_<characterName>.txt
 - outputFileName     is <bundle_root>/output/CRF/sorted_output_data_<characterID>_<characterName>.txt
 - detectionResultsFolder is <bundle_root>/detection_results/CRF/<characterID>/
 - datasetPath is <bundle_root>/
 - crfTempPath is <bundle_root>/output/CRF/temp
 - base_path is <crf_root_dir>
 - instance of ProgressIndicator

              
For DPM, information passed in is
                
 - list_of_characters  (list of simple characters)
 - input_folder  <bundleRoot>/input/DPM/<taxonID>/<simpleCharIDList>/<viewID>/sorted_input_data_<charID>_<charName>.txt
 - output_folder  <bundleRoot>/output/DPM/<taxonID>/<simpleCharIDList>/<viewID>/
 - detection_results_folder  <bundleRoot>/detection_results/DPM/<taxonID>/<simpleCharIDList>/<viewID>/
 - instance of ProgressIndicator
                

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
PHASE 3 - receiving information from algorithms
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Avatol system expects that the specified detection_results folder will be populated with files identical to the form
of the ANNOTATION files, which is
  
In  <charId>_<mediaId>.txt
 
    <coordinates>:<characterID>:<characterName>:<characterStateId>:<characterStateName>


For CRF, output information will be put into the specified file. 

For DPM, output files will be put in the specified directory.

Each output file will be named as

       sorted_output_data_<characterID>_<characterName>.txt

Each output file will have lines of the form 

      *training_data|<relative path of mediafile>|<characterStateID>|<characterStateName>|<relative path of annotation file>|<taxonID>|<line number in annotations file>
      image_scored|<relative path of mediafile>|<characterStateID>|<characterStateName>|<**relative path of annotation file>|<taxonID>|<***line number in annotations file>|<****score_confidence>
      image_not_scored|<relative path of mediafile>|<taxonID>|

*  training line verbatim from sorted_input_file
** relative path of annotation file for image_scored is the annotation file 
created that expresses detection results, so it will be under the 
detection_results dir.
*** if detection yields multiple instances of a part in a given image, then 
the generated annotation file will have multiple lines (one for each 
instance), just as the downloaded annotation files may have.
**** score_confidence - this will be discussed at the next team meeting.
